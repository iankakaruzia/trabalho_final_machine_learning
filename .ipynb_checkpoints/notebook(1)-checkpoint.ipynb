{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e5d2e1b5be530f6bc25e8bff280e28a4ad74a64"
   },
   "source": [
    "# Making predictions over amazon recommendation dataset\n",
    "\n",
    "## Predictions\n",
    "The purpose of this analysis is to make up a prediction model where we will be able to predict whether a recommendation is positive or negative. In this analysis, we will not focus on the Score, but only the positive/negative sentiment of the recommendation. \n",
    "\n",
    "To do so, we will work on Amazon's recommendation dataset, we will build a Term-doc incidence matrix using term frequency and inverse document frequency ponderation. When the data is ready, we will load it into predicitve algorithms, mainly naïve Bayesian and regression.\n",
    "\n",
    "In the end, we hope to find a \"best\" model for predicting the recommendation's sentiment.\n",
    "\n",
    "## Loading the data\n",
    "In order to load the data, we will use the SQLITE dataset where we will only fetch the Score and the recommendation summary. \n",
    "\n",
    "As we only want to get the global sentiment of the recommendations (positive or negative), we will purposefully ignore all Scores equal to 3. If the score id above 3, then the recommendation wil be set to \"postive\". Otherwise, it will be set to \"negative\". \n",
    "\n",
    "The data will be split into an training set and a test set with a test set ratio of 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "f115d851b91100a23236b209dfe5f3a0e7fd179b"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "con = sqlite3.connect('database.sqlite')\n",
    "\n",
    "messages = pd.read_sql_query(\"\"\"\n",
    "SELECT Score, Summary\n",
    "FROM Reviews\n",
    "WHERE Score != 3\n",
    "\"\"\", con)\n",
    "\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "Score = messages['Score']\n",
    "Score = Score.map(partition)\n",
    "Summary = messages['Summary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(Summary, Score, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2261d6b8e7ad40b71cda5881985756ef5f01b7e"
   },
   "source": [
    "## Brief Exploratory analysis\n",
    "\n",
    "After loading the data, here is what it looks like :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "64aefa326e57371fbb02df6bda0eb03fff097cb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Score                                            Summary\n",
      "0       5                              Good Quality Dog Food\n",
      "1       1                                  Not as Advertised\n",
      "2       4                              \"Delight\" says it all\n",
      "3       2                                     Cough Medicine\n",
      "4       5                                        Great taffy\n",
      "5       4                                         Nice Taffy\n",
      "6       5      Great!  Just as good as the expensive brands!\n",
      "7       5                             Wonderful, tasty taffy\n",
      "8       5                                         Yay Barley\n",
      "9       5                                   Healthy Dog Food\n",
      "10      5                    The Best Hot Sauce in the World\n",
      "11      5  My cats LOVE this \"diet\" food better than thei...\n",
      "12      1               My Cats Are Not Fans of the New Food\n",
      "13      4                                  fresh and greasy!\n",
      "14      5                       Strawberry Twizzlers - Yummy\n",
      "15      5           Lots of twizzlers, just what you expect.\n",
      "16      2                                         poor taste\n",
      "17      5                                           Love it!\n",
      "18      5                                 GREAT SWEET CANDY!\n",
      "19      5                            Home delivered twizlers\n"
     ]
    }
   ],
   "source": [
    "print(messages.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "934a3a596128a62ed88aead6f1032fa599cb6512"
   },
   "source": [
    "After splitting our dataset into X_train, X_test, Y_train, Y_test, we have no more integer score, but an appreciation of it : positive or negative :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c89da326d4597f77907c8b7ce010fab923a69745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Score                                            Summary\n",
      "0   positive                              Good Quality Dog Food\n",
      "1   negative                                  Not as Advertised\n",
      "2   positive                              \"Delight\" says it all\n",
      "3   negative                                     Cough Medicine\n",
      "4   positive                                        Great taffy\n",
      "5   positive                                         Nice Taffy\n",
      "6   positive      Great!  Just as good as the expensive brands!\n",
      "7   positive                             Wonderful, tasty taffy\n",
      "8   positive                                         Yay Barley\n",
      "9   positive                                   Healthy Dog Food\n",
      "10  positive                    The Best Hot Sauce in the World\n",
      "11  positive  My cats LOVE this \"diet\" food better than thei...\n",
      "12  negative               My Cats Are Not Fans of the New Food\n",
      "13  positive                                  fresh and greasy!\n",
      "14  positive                       Strawberry Twizzlers - Yummy\n",
      "15  positive           Lots of twizzlers, just what you expect.\n",
      "16  negative                                         poor taste\n",
      "17  positive                                           Love it!\n",
      "18  positive                                 GREAT SWEET CANDY!\n",
      "19  positive                            Home delivered twizlers\n"
     ]
    }
   ],
   "source": [
    "tmp = messages\n",
    "tmp['Score'] = tmp['Score'].map(partition)\n",
    "print(tmp.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb1221abfdd9770071b30059e0ac72b72c3d9a1c"
   },
   "source": [
    "## Cleaning the data\n",
    "\n",
    "To format our data and build the Term-doc incidence matrix, many operations will be performed on the data :\n",
    "- Stemming\n",
    "- Stop words removal\n",
    "- Lowering\n",
    "- Tokenization\n",
    "- Pruning (numbers and punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5e0443fa92b7640278ce44d8e5fd5000845d74d2"
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - '/home/ianka/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/home/ianka/anaconda3/nltk_data'\n    - '/home/ianka/anaconda3/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-db62c69b7af1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrantab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-db62c69b7af1>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#tokens = [word for word in tokens if word not in stopwords.words('english')]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstem_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - '/home/ianka/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/home/ianka/anaconda3/nltk_data'\n    - '/home/ianka/anaconda3/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    #tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return ' '.join(stems)\n",
    "\n",
    "intab = string.punctuation\n",
    "outtab = \"                                \"\n",
    "trantab = str.maketrans(intab, outtab)\n",
    "\n",
    "#--- Training set\n",
    "\n",
    "corpus = []\n",
    "for text in X_train:\n",
    "    text = text.lower()\n",
    "    text = text.translate(trantab)\n",
    "    text=tokenize(text)\n",
    "    corpus.append(text)\n",
    "        \n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(corpus)        \n",
    "        \n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "#--- Test set\n",
    "\n",
    "test_set = []\n",
    "for text in X_test:\n",
    "    text = text.lower()\n",
    "    text = text.translate(trantab)\n",
    "    text=tokenize(text)\n",
    "    test_set.append(text)\n",
    "\n",
    "X_new_counts = count_vect.transform(test_set)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "from pandas import *\n",
    "df = DataFrame({'Before': X_train, 'After': corpus})\n",
    "print(df.head(20))\n",
    "\n",
    "prediction = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ianka/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc39013222dbb1b3de0071123dd4eaf8bdf8dfc5"
   },
   "source": [
    "## Applying Multinomial Naïve Bayes learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9181839202ef26a8d0d09b06987632b64d181b19",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "prediction['Multinomial'] = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1492ae9af11e46e407d1a185d05c88b70917dd51"
   },
   "source": [
    "## Applying Bernoulli Naïve Bayes learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82e54dc0f834737f2059f15778303f741d230456",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB().fit(X_train_tfidf, y_train)\n",
    "prediction['Bernoulli'] = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bbd7fa343f1dc917755e9402ca956d6e58b16156"
   },
   "source": [
    "## Applying Logistic regression learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb8fb0b9858a41eecbd2e08b72bb664fdad611ab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "prediction['Logistic'] = logreg.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "583bb03ee83ad41bc21d69c55891b11300029e27"
   },
   "source": [
    "## Results\n",
    "\n",
    "In order to compare our learning algorithms, let's build the ROC curve. The curve with the highest AUC value will show our \"best\" algorithm.\n",
    "\n",
    "In first data cleaning, stop-words removal has been used, but the results were much worse. Reason for this result could be that when people want to speak about what is or is not good, they use many small words like \"not\" for instance, and these words will typically be tagged as stop-words, and will be removed. This is why in the end, it was decided to keep the stop-words. For those who would like to try it by themselves, I have let the stop-words removal as a comment in the cleaning part of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fcf22af6d555c7980377f64db3bee72e1581ffcf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formatt(x):\n",
    "    if x == 'negative':\n",
    "        return 0\n",
    "    return 1\n",
    "vfunc = np.vectorize(formatt)\n",
    "\n",
    "cmp = 0\n",
    "colors = ['b', 'g', 'y', 'm', 'k']\n",
    "for model, predicted in prediction.items():\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test.map(formatt), vfunc(predicted))\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    plt.plot(false_positive_rate, true_positive_rate, colors[cmp], label='%s: AUC %0.2f'% (model,roc_auc))\n",
    "    cmp += 1\n",
    "\n",
    "plt.title('Classifiers comparaison with ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f6da996731b29212ffc9031178de6f20fdbe63e3"
   },
   "source": [
    "After plotting the ROC curve, it would appear that the Logistic regression method provides us with the best results, although the AUC value for this method is not outstanding... \n",
    "\n",
    "Let's focus on logistic regression, and vizualise the accuracy, recall and confusion matrix of this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f388e594d78b11d58903ac2d48b29dcb21626b1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, prediction['Logistic'], target_names = [\"positive\", \"negative\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69d4cb37e2d70bc64366eb78e1f07615a3e46b8c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(set(Score)))\n",
    "    plt.xticks(tick_marks, set(Score), rotation=45)\n",
    "    plt.yticks(tick_marks, set(Score))\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, prediction['Logistic'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm)    \n",
    "\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
